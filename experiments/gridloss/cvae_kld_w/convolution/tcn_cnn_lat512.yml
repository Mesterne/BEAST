experiment_results_dir: experiments/gridloss/results
dataset_args:
  directory: data/gridloss
  training_data: train.csv
  test_data: test.csv
  window_size: 192
  mts_size: 576
  uts_size: 192
  step_size: 24
  timeseries_to_use:
    - grid1-load
    - grid1-loss
    - grid1-temp
  test_timeseries_to_use:
    - grid2-load
    - grid2-loss
    - grid2_1-temp
  num_features_per_uts: 4
  use_one_hot_encoding: false
  use_identity_mapping: false
  test_set_sample_size: 500
stl_args:
  series_periodicity: 24
model_args:
  genetic_algorithm_args:
    num_runs: 1
    num_generations: 100
    num_parents_mating: 2
    solutions_per_population: 10
    init_range_low: -5
    init_range_high: 5
    parent_selection_type: "sss"
    crossover_type: "single_point"
    mutation_type: "random"
    mutation_percent_genes: 25
    legal_values:
      trend_det_factor: [0.01, 10]
      trend_slope_factor: [-1, 1]
      trend_lin_factor: [0.01, 10]
      seasonal_det_factor: [0.01, 10]
  feature_model_args:
    model_name: mts_cvae
    input_size: 24
    output_size: 12
    hidden_network_sizes:
      - 256
    training_args:
      num_epochs: 20
      batch_size: 64
      learning_rate: 0.0001
      early_stopping_patience: 10
    conditional_gen_model_args:
      architecture: "convolution" # rnn, feedforward, rnn_enc_dec, convolution, attention
      condition_type: "feature_delta"
      input_size_without_conditions: 576
      output_size: 576
      latent_size: 512
      rnn_hidden_state_size: None
      convolutional_layers: # in_channels, out_channels, kernel_size, stride (padding from kernel_size - 1 and dilation doubles each layer)
        - [3, 8, 5, 1]
        - [8, 16, 5, 1]
        - [16, 32, 5, 1]
        - [32, 64, 5, 1]
      transformer_args:
        num_heads: 1
        num_layers: 2
        dim_model: 8
        dim_feedforward: 256
        dropout_rate: 0.1
        activation: "relu"
      number_of_conditions: 12
      feedforward_layers:
        - [512, relu]
        - [512, relu]
        - [256, relu]
        - [256, relu]
        - [128, relu]
      conv_decoder:
        use_conv_decoder: true
        feedforward_layers:
          - [128]
          - [256]
          - [512]
        conv_transpose_layers:
          - [16, 16, 5, 1]
          - [16, 8, 5, 1]
          - [8, 8, 5, 1]
          - [8, 3, 5, 1]
  forecasting_model_args:
    model_type: n_linear
    window_size: 168
    horizon_length: 24
    training_args:
      num_epochs: 50
