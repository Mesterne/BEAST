experiment_results_dir: experiments/gridloss/results
dataset_args:
  directory: data/gridloss
  training_data: train.csv
  test_data: test.csv
  window_size: 192
  mts_size: 576
  uts_size: 192
  step_size: 24
  timeseries_to_use:
    - grid1-load
    - grid1-loss
    - grid1-temp
  num_features_per_uts: 4
  use_one_hot_encoding: false
  use_identity_mapping: true
  test_set_sample_size: 500
stl_args:
  series_periodicity: 24
model_args:
  genetic_algorithm_args:
    num_runs: 1
    num_generations: 100
    num_parents_mating: 2
    solutions_per_population: 10
    init_range_low: -5
    init_range_high: 5
    parent_selection_type: "sss"
    crossover_type: "single_point"
    mutation_type: "random"
    mutation_percent_genes: 25
    legal_values:
      trend_det_factor: [0.01, 10]
      trend_slope_factor: [-1, 1]
      trend_lin_factor: [0.01, 10]
      seasonal_det_factor: [0.01, 10]
  feature_model_args:
    model_name: mts_cvae
    input_size: 24
    output_size: 12
    hidden_network_sizes:
      - 256
    training_args:
      num_epochs: 20
      batch_size: 64
      learning_rate: 0.0001
      early_stopping_patience: 50
    conditional_gen_model_args:
      architecture: "convolution" # rnn, feedforward, rnn_enc_dec, convolution, attention
      condition_type: "feature"
      input_size_without_conditions: 576
      latent_size: 64
      rnn_hidden_state_size: None
      convolutional_layers: # in_channels, out_channels, kernel_size, stride (padding from kernel_size - 1 and dilation doubles each layer)
        - [3, 8, 5, 1]
        - [8, 16, 5, 1]
        - [16, 32, 5, 1]
        - [32, 64, 5, 1]
      number_of_conditions: 12
      feedforward_layers:
        - [512, relu]
        - [512, relu]
        - [256, relu]
        - [256, relu]
        - [128, relu]
  forecasting_model_args:
    window_size: 168
    network_size:
      - 100
      - 100
    horizon_length: 24
    model_name: feedforward_forecaster
    model_params_storage_dir: models/feedforward
    training_args:
      num_epochs: 50
      batch_size: 128
      learning_rate: 0.001
      early_stopping_patience: 25
